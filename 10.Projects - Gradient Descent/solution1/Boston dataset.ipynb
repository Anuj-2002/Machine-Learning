{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 13)\n",
      "(379, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "training_data=np.loadtxt('0000000000002417_training_boston_x_y_train.csv', delimiter=',')\n",
    "testing_data=np.loadtxt('0000000000002417_test_boston_x_test.csv', delimiter=',')\n",
    "print(testing_data.shape)\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_grad(points, learn_rate, M):\n",
    "    N = points.shape[0]\n",
    "    num_col = points.shape[1]\n",
    "    \n",
    "    new_M = np.zeros(num_col)\n",
    "    \n",
    "    for i in range(N):\n",
    "        x = points[i, 0:num_col-1]\n",
    "        x = np.append(x, 1)\n",
    "        y = points[i, num_col-1]\n",
    "        for j in range(num_col):\n",
    "            new_M[j] += (-2/N) * (y - (M * x).sum()) * x[j]\n",
    "        M = M - (learn_rate * new_M)\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(points, learn_rate, num_iter):\n",
    "    num_col = points.shape[1]\n",
    "    M = np.zeros(num_col)\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        M = step_grad(points, learn_rate, M)\n",
    "#         if i % 100== 0:\n",
    "#             print(i, \"Cost= \", cost(points, M))\n",
    "    print(i, \"Cost= \", cost(points, M))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(points, M):\n",
    "    total_cost = 0\n",
    "    \n",
    "    N = points.shape[0]\n",
    "    num_col = points.shape[1]\n",
    "    \n",
    "    for i in range(N):\n",
    "        x = points[i,0:num_col-1]\n",
    "        x = np.append(x, 1)\n",
    "        y = points[i,num_col-1]\n",
    "        total_cost += (y - (M * x).sum()) ** 2\n",
    "        \n",
    "    total_cost = (1/N) * total_cost\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Cost=  25.541343677214176\n",
      "[-0.84624984  0.40135832 -0.82474138  0.76410138 -0.6559632   3.24805879\n",
      "  0.2120506  -1.50017462  0.79243382 -0.36060042 -1.54221503  0.66251249\n",
      " -3.59342772] 22.03562487394201\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    learning_rate = 0.0001\n",
    "    num_iterations = 100\n",
    "    m = gd(training_data, learning_rate, num_iterations)\n",
    "    #print(m, c)\n",
    "    return m[0:13], m[13]\n",
    "\n",
    "m,c=run()\n",
    "print(m,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = training_data[:, :-1]\n",
    "Y_train = training_data[:, -1]\n",
    "\n",
    "alg1 = LinearRegression()\n",
    "alg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=training_data[:, :13]\n",
    "# Y_train=training_data[:, 13:]\n",
    "# X_test=testing_data\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg1=LinearRegression()\n",
    "alg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.43328344, 29.03367318, 22.37164455, 24.47778655, 20.60166977,\n",
       "        2.72533175, 30.40000409, 24.86120042, 18.65724977, 23.53985838,\n",
       "       24.11396872, 17.71143854, 17.44000298, 21.65356278, 42.31137694,\n",
       "       23.84974493, 24.47573232, 27.53872655, 20.23606694, 31.15155453,\n",
       "       23.78237904, 25.00979443, 33.95768541, 36.43515649, 32.04098329,\n",
       "       16.71322632, 23.47176611, 32.93828009, 25.1807008 , 33.71008685,\n",
       "       16.88580202, 26.02760837, 23.27040025, 25.47758968, 15.00946631,\n",
       "       29.5857494 , 26.24821245, 20.37245654, 24.43681498,  9.44706894,\n",
       "        8.38096654, 29.01392345, 29.59085403, 19.7575697 , 20.3719679 ,\n",
       "        3.14442625, 39.52420118, 25.71741222, 30.37729628, 16.79453264,\n",
       "       17.89088652, 41.02574533, 17.57238787, 20.89662584, 15.59837696,\n",
       "       21.41394912, 18.4543645 , 23.1557639 , 13.67245022, 17.23573882,\n",
       "       15.02710365, 29.15131353, 25.17166386, 25.49749375, 17.21186687,\n",
       "       17.42936995, 34.70372763, 17.01340803, 27.10724289, 22.54695733,\n",
       "       29.25336918, 27.11018136, 17.73402192,  5.74704758, 36.87653877,\n",
       "       25.09193905, 30.15053651, 27.24080949, 16.2521844 , 32.63542161,\n",
       "       19.2735139 , 22.65416762, 22.22935077,  8.55084956, 17.33054362,\n",
       "       29.17591713, 27.20836198,  5.88576932, 21.91465626, 20.1154985 ,\n",
       "       22.17673963, 20.52700516, 20.85181227, 13.18132049, 19.69404919,\n",
       "       25.98666769, 40.27067742, 19.77706447, 33.70256574, 27.22074149,\n",
       "       28.74517137, 22.11543887, 25.9135196 , 31.30678414, 17.15297459,\n",
       "       26.37137846, 21.44656977, 36.73924503, 22.08272916, 16.70906176,\n",
       "       27.59458133, -0.05974722, 13.86188045, 16.28772152, 35.77134424,\n",
       "       20.85214459, 20.77286833, 25.35136054, 21.78782121, 18.84720303,\n",
       "       13.5148908 , 35.61958302, 23.09139597, 25.01812898, 17.46493171,\n",
       "       20.73709865, 14.72993727])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_pred = alg1.predict(testing_data)\n",
    "Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This function is used to find the best fit line using the training data\n",
    "# def fit(x_train, y_train):\n",
    "#     num = (x_train * y_train).mean() - x_train.mean() * y_train.mean()\n",
    "#     den = (x_train ** 2).mean() - x_train.mean() ** 2\n",
    "#     m = num / den\n",
    "#     c = y_train.mean() - m * x_train.mean()\n",
    "#     return m, c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function predicts the value of 'y' corresponding to each 'x'\n",
    "def predict(x, m, c):\n",
    "    N = x.shape[0]\n",
    "    y = np.zeros(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        X = x[i,:]\n",
    "        y[i] = (m * X).sum() + c\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.3881593 , 27.30656125, 21.94498917, 23.27228112, 20.67259791,\n",
       "        3.00780178, 28.20068558, 23.46443335, 18.63246932, 22.18134381,\n",
       "       24.02598461, 18.44303227, 19.57896399, 21.02498499, 41.78133577,\n",
       "       23.33702575, 22.99980109, 26.64759404, 19.78378991, 30.99574501,\n",
       "       23.10633271, 22.33020981, 31.58069688, 33.90184545, 31.70950883,\n",
       "       14.12213674, 21.20091551, 30.94480357, 22.94739229, 32.29063842,\n",
       "       17.86860236, 24.25912554, 23.60558585, 25.02848436, 14.77935765,\n",
       "       27.87786845, 25.21776364, 20.47332291, 23.60302131,  9.85585532,\n",
       "        4.92116468, 27.0633329 , 28.4240106 , 20.27326046, 19.55317578,\n",
       "        1.27755548, 39.91220767, 25.48375174, 30.81045028, 17.4249942 ,\n",
       "       16.79064868, 38.75247336, 18.19269379, 19.99490497, 16.79301558,\n",
       "       21.12992938, 18.0937422 , 21.97528558, 14.4115086 , 17.24506526,\n",
       "       13.93010994, 28.34947092, 24.08411118, 25.09395101, 16.08982441,\n",
       "       14.49735932, 33.75580854, 17.28021995, 24.40991195, 21.28275835,\n",
       "       28.24877543, 24.65748078, 18.08290288,  4.20427507, 35.27350413,\n",
       "       24.54223182, 27.71676511, 25.32122053, 15.59031752, 32.10535818,\n",
       "       19.48140714, 22.91001842, 22.29889746,  9.01880126, 17.50349394,\n",
       "       29.91686511, 26.99399856,  4.81051633, 18.7033565 , 19.24327002,\n",
       "       20.59410621, 20.4127527 , 20.49369816, 13.86182608, 19.98790596,\n",
       "       26.74499425, 39.02557259, 16.80692877, 32.36330577, 25.60734427,\n",
       "       25.64141104, 21.9516013 , 23.9678883 , 29.58651181, 17.48879403,\n",
       "       24.6838651 , 21.12959615, 36.46867661, 22.2930867 , 16.23882776,\n",
       "       27.14553028, -2.05736236, 13.76295898, 13.918057  , 35.59472246,\n",
       "       20.76095076, 22.37553078, 23.98011157, 21.35920102, 18.6126068 ,\n",
       "       14.7157412 , 32.58569378, 21.30368093, 22.54606983, 20.10815281,\n",
       "       20.46411889, 14.48146843])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = testing_data\n",
    "y_pred = predict(x_test, m, c)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.081252971153916"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m, c = fit(X_train, Y_train)\n",
    "# # Test data\n",
    "# Y_test_pred = predict(X_test, m, c)\n",
    "\n",
    "y_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('predictions.csv', Y_test_pred, delimiter=',', fmt='%.5f')\n",
    "np.savetxt(\"predictedboston2notscaled0.0001.csv\", y_pred, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
